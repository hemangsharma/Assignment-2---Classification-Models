{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cfefa62",
   "metadata": {},
   "source": [
    "Sure, I can help you with that. Here's an example code to build a KNN model for the given dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5be45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cad231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"repurchase_training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76167778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"age_band\", axis=1, inplace=True)\n",
    "# Drop the ID column as it doesn't provide any valuable information\n",
    "df.drop(\"ID\", axis=1, inplace=True)\n",
    "\n",
    "# Encode the categorical variables\n",
    "le = LabelEncoder()\n",
    "df[\"gender\"] = le.fit_transform(df[\"gender\"])\n",
    "df[\"car_model\"] = le.fit_transform(df[\"car_model\"])\n",
    "df[\"car_segment\"] = le.fit_transform(df[\"car_segment\"])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop(\"Target\", axis=1)\n",
    "y = df[\"Target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee06aaa",
   "metadata": {},
   "source": [
    "You can fine-tune the hyperparameters of the KNN model by adjusting the value of n_neighbors and experimenting with different distance metrics. You can also use cross-validation techniques to select the best value for n_neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd09f40b",
   "metadata": {},
   "source": [
    "Sure, here's an example of how you can fine-tune the hyperparameters of a KNN model in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load the data and split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the grid of hyperparameters to search over\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Perform a grid search with cross-validation to find the best hyperparameters\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding cross-validation score\n",
    "print('Best hyperparameters:', grid.best_params_)\n",
    "print('Cross-validation score:', grid.best_score_)\n",
    "\n",
    "# Evaluate the performance of the best model on the test set\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "print('Classification report:\\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34c38e",
   "metadata": {},
   "source": [
    "In this example, we first define the KNN classifier and the hyperparameters to search over. We then use GridSearchCV to perform a grid search with cross-validation, which tests all combinations of hyperparameters in param_grid and finds the combination that produces the best cross-validation score. We print the best hyperparameters and cross-validation score, and then evaluate the performance of the best model on the test set using confusion_matrix and classification_report.\n",
    "\n",
    "Note that this example assumes that you have already loaded and split the data into X_train, X_test, y_train, and y_test variables. You will also need to replace ... with the appropriate code to load and split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73abb9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting the distribution of the target variable\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Target variable distribution')\n",
    "\n",
    "# Plotting the correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), cmap='coolwarm', annot=True)\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "# Plotting the validation curve\n",
    "param_range = range(1, 20, 2)\n",
    "train_scores, test_scores = validation_curve(KNeighborsClassifier(), X_train, y_train, param_name=\"n_neighbors\", param_range=param_range, cv=5)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(param_range, np.mean(train_scores, axis=1), label='Training score')\n",
    "plt.plot(param_range, np.mean(test_scores, axis=1), label='Cross-validation score')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.title('Validation Curve')\n",
    "\n",
    "# Plotting the learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(KNeighborsClassifier(n_neighbors=5), X_train, y_train, cv=5)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training score')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Cross-validation score')\n",
    "plt.xlabel('Training set size')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.title('Learning Curve')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
